```{r, include=FALSE}
# Nettoyage de l'environnement
rm(list = ls())

# Chargement des librairies
library(dplyr)
library(corrplot)
library(Exact) 
library(ggplot2)
library(DescTools)

# install.packages("Exact")
# install.packages("DescTools")

# Définition du répertoire de travail
setwd("/home/rogerbernat/Documents/Projet_statistique_2024")

# Chargement du fichier .rds
data <- readRDS("donnees_etape_1_1.Rdata", "rb")
nom_colonnes <- colnames(data)
```


## Étude univariée du lien entre Y et les variables X
On commence par définir une fonction qui réalise un test du chi^2 pour les variables qualitatives dont la modalité ayant le plus petit effectif est supérieure à 5. Sinon, on effectue un G-test. Pour les variables numériques, on applique un test ANOVA.
```{r, warning=FALSE}
# Fonction d'étude univariée
etude_univariee <- function(Y, data) {
  if (!(Y %in% colnames(data))) {
    stop("La variable Y n'est pas présente dans le jeu de données.")
  }
  
  variables_selectionnees <- list()
  
  for (var in colnames(data)) {
    if (var == Y) next 
    
    if (is.numeric(data[[var]])) {
      p_value <- tryCatch({
        summary(aov(data[[var]] ~ data[[Y]]))[[1]]$`Pr(>F)`[1]
      }, error = function(e) NA)
      
    } else if (is.factor(data[[var]])) {
      tab_contingence <- table(data[[var]], data[[Y]])
      if (any(tab_contingence < 5)) {
        p_value <- tryCatch({
          GTest(tab_contingence)$p.value
          }, error = function(e) NA)
      } else {
        p_value <- tryCatch({
          chisq.test(tab_contingence)$p.value
        }, error = function(e) NA)
      }
      
    } else {
      next
    }
    
    if (!is.na(p_value)) {
      variables_selectionnees[[var]] <- p_value
    }
  }
  
  return(variables_selectionnees)
}
```

## Sélection des variables explicatives
```{r, warning=FALSE}
resultats <- etude_univariee(Y = colnames(data)[511], data = data)

p_values <- as.numeric(unlist(resultats))
top_100_p_value <- p_values[order(p_values)][100]

density_values <- density(p_values)

valid_range <- density_values$x >= 0 & density_values$x <= 0.23
filtered_density_x <- density_values$x[valid_range]
filtered_density_y <- density_values$y[valid_range]

slopes <- diff(filtered_density_y)
local_max_x <- filtered_density_x[which.min(slopes)]


# Create a density plot
ggplot(data.frame(p_values), aes(x = p_values)) +
  geom_density(fill = "blue", alpha = 0.5) +
  geom_vline(xintercept = top_100_p_value, color = "red", linetype = "dashed", size = 1) +
  # geom_vline(xintercept = local_max_x, color = "orange", linetype = "dashed", size = 1) +
  labs(title = "Densité des P-valeurs",
       x = "p-valeur",
       y = "Densité") +
  theme_minimal()

ggplot(data.frame(p_values), aes(x = p_values)) +
  stat_ecdf(geom = "step", color = "blue", size = 1) +
  geom_vline(xintercept = top_100_p_value, color = "red", linetype = "dashed", size = 1)  +
  # geom_vline(xintercept = local_max_x, color = "orange", linetype = "dashed", size = 1) +
  labs(title = "Densité cumulée des p-valeurs",
       x = "P-Valeur",
       y = "Probabilité cumulée") +
  theme_minimal()

top_100_p_value
```

En gardant une p-valeur de 0.17, nous sélectionnons les 100 valeurs les plus corrélées avec la variable d'intérêt.  

Cependant, comme nous avons utilisé la même p-valeur pour des variables de nature différente, vérifions si les variables sélectionnées respectent les proportions initiales de typage.

```{r}
variable_names <- names(resultats)

# Transformation en data frame
p_values_df <- data.frame(variable = variable_names, p_value = p_values)

# On met les variables en ordre suivant la p_valeur
sorted_p_values_df <- p_values_df[order(p_values_df$p_value), ]

# On garde les indices des 100 avec la lus petite p valeur
top_100_variables <- sorted_p_values_df[c(1:100),]

p_100_data <- data[, c(top_100_variables$variable, "y")]

column_types <- sapply(data, class)

comparation_typage_dataframe <- function(df1, df2) {
  # On crée une variable de type 
  types_df1 <- sapply(df1, class)
  types_df2 <- sapply(df2, class)
  
  # On calcule la proportion des types
  type_proportions_df1 <- table(types_df1) / length(types_df1)
  type_proportions_df2 <- table(types_df2) / length(types_df2)
  
  # On regarde qu'il n'y ait pas une table avec un type de moins
  all_types <- unique(c(names(type_proportions_df1), names(type_proportions_df2)))
  
  # On crée le dataframe de comparaison
  comparison_df <- data.frame(
    DataType = all_types,
    Proportion_df1 = sapply(all_types, function(x) type_proportions_df1[x]),
    Proportion_df2 = sapply(all_types, function(x) type_proportions_df2[x])
  )
  
  # On remplace les valeurs manquantes par 0
  comparison_df$Proportion_df1[is.na(comparison_df$Proportion_df1)] <- 0
  comparison_df$Proportion_df2[is.na(comparison_df$Proportion_df2)] <- 0
  
  return(comparison_df)
}
comparison_df <- comparation_typage_dataframe(data, p_100_data)
comparison_df
```

On observe des différences notables de répartition. Vérifions ces observations à l’aide du test du chi^2 :

```{r}
var_1 <- comparison_df$Proportion_df1[2:3]
var_2 <- comparison_df$Proportion_df2[2:3]
tab_contingence <- matrix(c(var_1, var_2), 
                            nrow = 2, 
                            byrow = TRUE)
chisq.test(tab_contingence*100)
```

On a une p-valeur de 0,05. Donc, les variables ne sont pas indépendantes. Cependant, aurait-il été plus judicieux de choisir les variables en respectant les proportions initiales de la base de données ?

```{r, include=FALSE, eval=FALSE}
summary(p_100_data)
saveRDS(p_100_data, "donnees_etape_2.Rdata")
```