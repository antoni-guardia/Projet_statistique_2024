```{r, include=FALSE}
# Nettoyage de l'environnement
rm(list = ls())

# Chargement des librairies
library(dplyr)
library(corrplot)
library(Exact) 
library(ggplot2)
library(DescTools)

# install.packages("Exact")
# install.packages("DescTools")

# Définition du répertoire de travail
setwd("/home/rogerbernat/Documents/Projet_statistique_2024")

# Chargement du fichier .rds
donnees <- readRDS("nomenclature_y_supp_anciennes.Rdata", "rb")
data <- donnees[, -1]
nom_colonnes <- colnames(data)
```


## Étude univariée du lien entre Y et les variables X
On commence par définir une fonction qui réalise un test du chi^2 pour les variables qualitatives dont la modalité ayant le plus petit effectif est supérieure à 5. Sinon, on effectue un G-test. Pour les variables numériques, on applique un test ANOVA.
```{r, warning=FALSE}
# Fonction d'étude univariée
etude_univariee <- function(Y, data) {
  if (!(Y %in% colnames(data))) {
    stop("La variable Y n'est pas présente dans le jeu de données.")
  }
  
  variables_selectionnees <- list()
  
  for (var in colnames(data)) {
    if (var == Y) next 
    
    if (is.numeric(data[[var]])) {
      p_value <- tryCatch({
        summary(aov(data[[var]] ~ data[[Y]]))[[1]]$`Pr(>F)`[1]
      }, error = function(e) NA)
      
    } else if (is.factor(data[[var]])) {
      tab_contingence <- table(data[[var]], data[[Y]])
      if (any(tab_contingence < 5)) {
        p_value <- tryCatch({
          GTest(tab_contingence)$p.value
          }, error = function(e) NA)
      } else {
        p_value <- tryCatch({
          GTest(tab_contingence)$p.value
        }, error = function(e) NA)
      }
      
    } else {
      next
    }
    
    if (!is.na(p_value)) {
      variables_selectionnees[[var]] <- p_value
    }
  }
  
  return(variables_selectionnees)
}
```

## Sélection des variables explicatives
```{r, warning=FALSE}
resultats <- etude_univariee(Y = colnames(data)[510], data = data)

p_values <- as.numeric(unlist(resultats))
p_select <- 0.1

density_values <- density(p_values)

ggplot(data.frame(p_values), aes(x = p_values)) +
  geom_density(fill = "blue", alpha = 0.5) +
  geom_vline(xintercept = p_select, color = "red", linetype = "dashed", size = 1) +
  # geom_vline(xintercept = local_max_x, color = "orange", linetype = "dashed", size = 1) +
  labs(title = "Densité des P-valeurs",
       x = "p-valeur",
       y = "Densité") +
  theme_minimal()

ggplot(data.frame(p_values), aes(x = p_values)) +
  stat_ecdf(geom = "step", color = "blue", size = 1) +
  geom_vline(xintercept = p_select, color = "red", linetype = "dashed", size = 1)  +
  # geom_vline(xintercept = local_max_x, color = "orange", linetype = "dashed", size = 1) +
  labs(title = "Densité cumulée des p-valeurs",
       x = "P-Valeur",
       y = "Probabilité cumulée") +
  theme_minimal()
length(p_values[p_values <= p_select])
```

En gardant une p-valeur de 0,10, nous sélectionnons 61 variables. Nous faisons ce choix de p-valeur afin de limiter à 10 % les chances de nous tromper lors de la considération ou non d’une variable.

Cependant, comme nous avons utilisé la même p-valeur pour des variables de nature différente, vérifions si les variables sélectionnées respectent les proportions initiales de typage.

```{r}
variable_names <- names(resultats)

# Transformation en data frame
p_values_df <- data.frame(variable = variable_names, p_value = p_values)

# On met les variables en ordre suivant la p_valeur
sorted_p_values_df <- p_values_df[p_values_df$p_value <= p_select, ]

# On garde les indices des 100 avec la lus petite p valeur
p_100_data <- data[, c(sorted_p_values_df$variable, "y")]

column_types <- sapply(data, class)

comparation_typage_dataframe <- function(df1, df2) {
  # On crée une variable de type 
  types_df1 <- sapply(df1, class)
  types_df2 <- sapply(df2, class)
  
  # On calcule la proportion des types
  type_proportions_df1 <- table(types_df1) / length(types_df1)
  type_proportions_df2 <- table(types_df2) / length(types_df2)
  
  # On regarde qu'il n'y ait pas une table avec un type de moins
  all_types <- unique(c(names(type_proportions_df1), names(type_proportions_df2)))
  
  # On crée le dataframe de comparaison
  comparison_df <- data.frame(
    DataType = all_types,
    Proportion_df1 = sapply(all_types, function(x) type_proportions_df1[x]),
    Proportion_df2 = sapply(all_types, function(x) type_proportions_df2[x])
  )
  
  # On remplace les valeurs manquantes par 0
  comparison_df$Proportion_df1[is.na(comparison_df$Proportion_df1)] <- 0
  comparison_df$Proportion_df2[is.na(comparison_df$Proportion_df2)] <- 0
  
  return(comparison_df)
}
comparison_df <- comparation_typage_dataframe(data, p_100_data)
comparison_df
```

On observe des différences notables de répartition. Vérifions ces observations à l’aide du test du chi^2 :

```{r}
var_1 <- comparison_df$Proportion_df1
var_2 <- comparison_df$Proportion_df2

tab_contingence <- matrix(c(var_1, var_2), 
                            nrow = 2, 
                            byrow = TRUE)
chisq.test(tab_contingence*100)
length(p_100_data)
head(p_100_data)
```

On a une p-valeur de 0,04. Donc, les variables ne sont pas indépendantes. Cependant, aurait-il été plus judicieux de choisir les variables en respectant les proportions initiales de la base de données ?

```{r, include=FALSE, eval=T}
length(p_100_data)
p_100_data <- cbind(donnees$CODE_ELEVAGE, p_100_data)
colnames(p_100_data)[1] <- "CODE_ELEVAGE"
saveRDS(p_100_data, "supp_p_val_10.Rdata")
```